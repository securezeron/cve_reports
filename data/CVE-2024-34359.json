{"id": "CVE-2024-34359", "sourceIdentifier": "security-advisories@github.com", "published": "2024-05-14T15:38:45.093", "lastModified": "2024-05-14T16:12:23.490", "vulnStatus": "Awaiting Analysis", "cveTags": [], "descriptions": [{"lang": "en", "value": "llama-cpp-python is the Python bindings for llama.cpp. `llama-cpp-python` depends on class `Llama` in `llama.py` to load `.gguf` llama.cpp or Latency Machine Learning Models. The `__init__` constructor built in the `Llama` takes several parameters to configure the loading and running of the model. Other than `NUMA, LoRa settings`, `loading tokenizers,` and `hardware settings`, `__init__` also loads the `chat template` from targeted `.gguf` 's Metadata and furtherly parses it to `llama_chat_format.Jinja2ChatFormatter.to_chat_handler()` to construct the `self.chat_handler` for this model. Nevertheless, `Jinja2ChatFormatter` parse the `chat template` within the Metadate with sandbox-less `jinja2.Environment`, which is furthermore rendered in `__call__` to construct the `prompt` of interaction. This allows `jinja2` Server Side Template Injection which leads to remote code execution by a carefully constructed payload."}, {"lang": "es", "value": "llama-cpp-python son los enlaces de Python para llama.cpp. `llama-cpp-python` depende de la clase `Llama` en `llama.py` para cargar `.gguf` llama.cpp o modelos de aprendizaje autom\u00e1tico de latencia. El constructor `__init__` integrado en `Llama` toma varios par\u00e1metros para configurar la carga y ejecuci\u00f3n del modelo. Adem\u00e1s de `NUMA, configuraci\u00f3n de LoRa`, `carga de tokenizadores` y `configuraci\u00f3n de hardware`, `__init__` tambi\u00e9n carga la `plantilla de chat` desde los metadatos `.gguf` espec\u00edficos y adem\u00e1s la analiza en `llama_chat_format.Jinja2ChatFormatter.to_chat_handler ()` para construir el `self.chat_handler` para este modelo. Sin embargo, `Jinja2ChatFormatter` analiza la `plantilla de chat` dentro del Metadate con `jinja2.Environment` sin zona de pruebas, que adem\u00e1s se representa en `__call__` para construir el `mensaje` de interacci\u00f3n. Esto permite la inyecci\u00f3n de plantilla del lado del servidor `jinja2`, lo que conduce a la ejecuci\u00f3n remota de c\u00f3digo mediante un payload cuidadosamente construida."}], "metrics": {"cvssMetricV31": [{"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.6, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 2.8, "impactScore": 6.0}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-76"}]}], "references": [{"url": "https://github.com/abetlen/llama-cpp-python/commit/b454f40a9a1787b2b5659cd2cb00819d983185df", "source": "security-advisories@github.com"}, {"url": "https://github.com/abetlen/llama-cpp-python/security/advisories/GHSA-56xg-wfcc-g829", "source": "security-advisories@github.com"}], "techniques": [{"techniqueID": "T1190", "comment": "CVE-2024-34359 - This technique is relevant as it involves server-side template injection, which can lead to remote code execution. Defending against this requires implementing proper input validation and sanitization."}, {"techniqueID": "T1204", "comment": "CVE-2024-34359 - This technique is relevant as it involves using a vulnerable module/ component, which can be exploited to inject malicious code. Defending against this requires updating vulnerable components to the latest version and implementing proper INPUT validation."}, {"techniqueID": "T1059", "comment": "CVE-2024-34359 - This technique is relevant as it involves Command and Scripting interpreter, which can be used to execute malicious code. Defending against this requires implementing proper command and script interpreter whitelisting."}, {"techniqueID": "T1036", "comment": "CVE-2024-34359 - This technique is relevant as it involves using communication platforms, which can be used to exfiltrate data or receive commands. Defending against this requires implementing proper network monitoring and logging, as well as restricting access to sensitive data."}], "stix_bundle": {"$schema": "https://stix2.io/schema/2.1/stix/bundle.json", "type": "bundle", "objects": [{"type": "vulnerability", "id": "urn:CVE-CDE-1.2:2024-34359", "created_by_ref": "urn:org.stix2:stix", "description": {"value": "llama-cpp-python is the Python bindings for llama.cpp. `llama-cpp-python` depends on class `Llama` in `llama.py` to load `.gguf` llama.cpp or Latency Machine Learning Models.\n\nThe `__init__` constructor built in the `Llama` takes several parameters to configure the loading and running of the model. Other than `NUMA, LoRa settings`, `loading tokenizers,` and `hardware settings`, `__init__` also loads the `chat template` from targeted `.gguf` 's Metadata and furtherly parses it to `llama_chat_format.Jinja2ChatFormatter.to_chat_handler()` to construct the `self.chat_handler` for this model.\n\nNevertheless, `Jinja2ChatFormatter` parse the `chat template` within the Metadate with sandbox-less `jinja2.Environment`, which is furthermore rendered in `__call__` to construct the `prompt` of interaction. This allows `jinja2` Server Side Template Injection which leads to remote code execution by a carefully constructed payload."}, "cvssScore": 9.6, "cvssVector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H", "mitreATTCKTechniques": [{"name": "T1190", "label": "Exploitation of Remote Services - Execution with Command Shell"}, {"name": "T1204", "label": "Data Stewardship - Command and Scripting Interpreter"}, {"name": "T1059", "label": "Command and Scripting Interpreter"}, {"name": "T1036", "label": "Web Services - Communication"}, {"name": "T1199", "label": "Exploitation of Remote Services - Execution with Hijacked Interface"}], "description_refs": [{"href": "https://cve.mitre.org/data/downloads/index.html", "id": "CVE-2024-34359"}, {"href": "https://github.com/abetlen/llama-cpp-python/commit/b454f40a9a1787b2b5659cd2cb00819d983185df", "id": "GHSA-56xg-wfcc-g829"}], "references": [{"href": "https://cve.mitre.org/data/downloads/index.html", "id": "CVE-2024-34359"}, {"href": "https://github.com/abetlen/llama-cpp-python/commit/b454f40a9a1787b2b5659cd2cb00819d983185df", "id": "GHSA-56xg-wfcc-g829"}]}]}, "technical_analysis": {"Introduction": "The vulnerability exists in the llama-cpp-python library, a Python bindings for llama.cpp. The `__init__` constructor in the `Llama` class takes several parameters to configure the loading and running of the model.", "Impact and Scope": "The vulnerability allows server-side template injection, which can lead to remote code execution. The attack vector is NETWORK, and the attack complexity is LOW. The confidentiality impact is HIGH, integrity impact is HIGH, and availability impact is HIGH, resulting in a CVSS score of 9.6.", "Related MITRE ATT&CK Techniques": "The following MITRE ATT&CK techniques are relevant to this CVE: T1190, T1204, T1059, and T1036.", "Technical Details": "The vulnerability can be exploited by sending a carefully crafted payload to the llama-cpp-python library. The payload will be executed on the server, allowing an attacker to remotely execute code.", "Detection": "Detection of this vulnerability is possible by monitoring network traffic for suspicious requests and monitoring system logs for signs of exploitation.", "Mitigation": "Mitigation of this vulnerability involves implementing proper input validation and sanitization, keeping the llama-cpp-python library up to date, and restricting access to sensitive data.", "Conclusion": "In conclusion, it is crucial to address this vulnerability to prevent remote code execution and protect sensitive data."}, "executive_analysis": {"Overview": "The llama-cpp-python library contains a vulnerability that allows server-side template injection, which can lead to remote code execution.", "Business Impact": "The vulnerability can result in unauthorized access to sensitive data and create significant financial losses.", "Technical Impact": "The vulnerability allows an attacker to remotely execute code on the server, which can lead to data breaches, system compromise, and other serious security risks.", "Mitigation Strategies": "Implementing proper input validation and sanitization, keeping the llama-cpp-python library up to date, and restricting access to sensitive data are effective mitigation strategies.", "Recommendations": "We recommend that all organizations using the llama-cpp-python library take immediate action to address this vulnerability and implement the recommended mitigation strategies.", "Conclusions": "In conclusion, it is crucial for organizations to take proactive measures to address this vulnerability and ensure the security of their systems and data."}}